# -*- coding: utf-8 -*-
"""WebscrapingAndSummarizing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ArcFtkDXpbge7lXLwijvolBa86DuVVRS
"""

!pip install -q -U google-generativeai

import pathlib
import textwrap

import google.generativeai as genai

from IPython.display import display
from IPython.display import Markdown


def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

# Used to securely store your API key
from google.colab import userdata

# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel('gemini-pro')

from googlesearch import search
print("Googlesearch package installed successfully!")

# set query to search for in Google
query = input("Enter query: ")
# execute query and store search results
results = search(query, tld="com", lang="en", stop=int(input("Enter no. of links reqd.: ")), pause=2)
# results2 = results
# iterate over all search results and print them
# for result in results:
#     print(result)

import requests
from bs4 import BeautifulSoup

# Send an HTTP request to the URL of the webpage you want to access

# response = requests.get("https://www.example.com/")
# response = requests.get("https://en.wikipedia.org/wiki/Akshay_Kumar_Datta")
# response = requests.get("https://en.wikipedia.org/wiki/Ishwar_Chandra_Vidyasagar")

for result in results:
    response = requests.get(result)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, "html.parser")

# Extract the text content of the webpage
toxt = soup.get_text()

print(toxt)
print("\n_________________________________________________________________________________________________________________\n")

# %%time
strng = "Classify this data " + toxt
response = model.generate_content(strng)

to_markdown(response.text)